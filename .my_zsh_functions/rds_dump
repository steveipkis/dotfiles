#!/bin/bash
#
# Author: Bruno Coimbra <bbcoimbra@gmail.com>
#
# Backups database located in DB_HOST, DB_PORT, DB_NAME
# and can be accessed using DB_USER. Password should be
# located in $HOME/.pgpass and this file should be
# chmod 0600[1].
#
# Target bucket should be set in BACKUP_BUCKET variable.
#
# AWS credentials should be available as needed by aws-cli[2].
#
# Dependencies:
#
# * pg_dump executable (can be found in postgresql-client-<version> package)
# * aws-cli (with python environment configured execute 'pip install awscli')
#
#
# References
# [1] - http://www.postgresql.org/docs/9.3/static/libpq-pgpass.html
# [2] - http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html
#
#
###############

rds_dump() {

        ### Variables
        DB_HOST="dataeng-airflow-prod-postgres-rds.us-east-1.bamgrid.net"
        DB_PORT="5432"
        DB_NAME="airflow"
        DB_USER="airflow_user"

        ###############
        #
        # **RISK ZONE** DON'T TOUCH below this line unless you know
        #               exactly what you are doing.
        #
        ###############

        set -e

        export PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"    

        ### Variables

        TEMPFILE_PREFIX="db-$DB_NAME-backup"
        TEMPFILE="$(mktemp -t $TEMPFILE_PREFIX-XXXXXXXX)"
        DATE="$(date +%Y-%m-%d)"
        TIMESTAMP="$(date +%s)"
        BACKUPFILE="backup-$DB_NAME-$TIMESTAMP.sql.gz"
        LOGTAG="DB $DB_NAME Backup"

        ### Validations
        if [[ ! -r "$HOME/.pgpass" ]]; then
                echo "$LOGTAG" "$0: Can't find database credentials. $HOME/.pgpass file isn't readable. Aborted."
                exit 1
        fi

        if ! which pg_dump > /dev/null; then
                echo "$LOGTAG" "$0: Can't find 'pg_dump' executable. Aborted."
                exit 1
        fi

        echo "$LOGTAG" "$0: remove any previous dirty backup file" | bat -l rs
        rm -f /tmp/$TEMPFILE_PREFIX* || true

        ### Generate dump and compress it
        echo "$LOGTAG"  "Dumping Database..." | bat -l rs
        pg_dump -O -x -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -w "$DB_NAME" > "$TEMPFILE"
        echo "$LOGTAG"  "Dumped." | bat -l rs
        echo "$LOGTAG"  "Compressing file..." | bat -l rs
        nice gzip -9 "$TEMPFILE"
        echo "$LOGTAG"  "Compressed." | bat -l rs
        mv "$TEMPFILE.gz" "$BACKUPFILE"

        # ### Upload it to S3 Bucket and cleanup
        # bat "$LOGTAG"  "Uploading '$BACKUPFILE' to S3..."
        # aws s3 cp "$BACKUPFILE" "s3://$S3_BACKUP_BUCKET/$DATE/$BACKUPFILE"
        # bat "$LOGTAG"  "Uploaded."

        ### Cleanup the data and remove them from the local machine
        bat "$LOGTAG"  "Clean-up..."
        rm -f $TEMPFILE
        rm -f /tmp/$TEMPFILE_PREFIX*
        bat "$LOGTAG" "Finished."

        exit 0
}